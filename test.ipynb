{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d224c669",
   "metadata": {},
   "source": [
    "## **Feroz Khan** \n",
    "\n",
    "## YOLO11:\n",
    "\n",
    "\n",
    "#### Envronment setup:\n",
    "\n",
    "\tpy -3.10 -m venv myvenv\n",
    "\t\n",
    "\tmyvenv\\Scripts\\activate\n",
    "\t\n",
    "##### Ultralytics recommend to install pytorch first from official website as per your cuda version-  https://pytorch.org/get-started/locally.\n",
    "\n",
    "\tpip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "    \n",
    "\tpip install Ultralytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d8c18",
   "metadata": {},
   "source": [
    "New Version of You Only Look Once (YOLO) \n",
    "\n",
    "Introducing Ultralytics YOLO11, the latest version of the acclaimed real-time object detection and image segmentation model. \n",
    "\n",
    "Ultralytics YOLO11 is a cutting-edge, state-of-the-art (SOTA) model that builds upon the success of previous YOLO versions and introduces new features and improvements to further boost performance and flexibility. YOLO11 is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection and tracking, instance segmentation, image classification and pose estimation tasks.\n",
    "\n",
    "![graph](graph.png)\n",
    "\n",
    "Installation: \n",
    "pip install ultralytics \n",
    "\n",
    "Models: \n",
    "\n",
    "YOLO11 Detect, Segment and Pose models pretrained on the COCO dataset are available here, as well as YOLO11 Classify models pretrained on the ImageNet dataset. Track mode is available for all Detect, Segment and Pose models. \n",
    "\n",
    "Ultralytics YOLO supported tasks\n",
    "\n",
    "#### Segments\n",
    "\n",
    "![segment](segments.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd522017-c4c6-477c-8a31-591a41a3f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\") # this is smallest object detection model\n",
    "\n",
    "# Perform object detection on an image\n",
    "results = model(\"test.jpeg\")\n",
    "results[0].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149c5d8-2993-4d9b-b3cd-3d05205c08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\") \n",
    "\n",
    "# Perform object detection on an image\n",
    "results = model(\"vid.mp4\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# # Load a model\n",
    "# model = YOLO(\"YOLO11n.pt\") \n",
    "\n",
    "# # Perform object detection on an image\n",
    "# results = model(0, save=True)\n",
    "# # results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0723058d-c0c9-40ad-b1b7-89a454623738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"YOLO11n-seg.pt\") \n",
    "\n",
    "# Perform object detection on an image\n",
    "results = model(\"test.jpeg\") # for video change the path for your video\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03328052-1282-42a6-8713-eea8e031e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"YOLO11n-pose.pt\") \n",
    "\n",
    "# Perform object detection on an image\n",
    "results = model(\"test.jpeg\", save=True)\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1da29e-c320-4a81-914b-1c9379118b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"YOLO11n-cls.pt\") \n",
    "\n",
    "# Perform object detection on an image\n",
    "results = model(\"coffee.png\", save=True)\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5220c99-dabb-4098-8cf4-59a5f23b9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"YOLO11n-obb.pt\") \n",
    "\n",
    "# Perform object detection on an image\n",
    "results = model(\"vid1.mp4\", save=True)\n",
    "#results[0].save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f03b2e-f535-4de4-967d-4affe11a7fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
